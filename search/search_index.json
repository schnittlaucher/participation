{"config":{"lang":["en","de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"concept/","title":"Concept","text":"<p>DemocracySim is a multi-agent simulation framework designed to explore the effects of different voting rules on democratic participation and welfare. Developed as part of a master's thesis at Leipzig University, the project investigates how collective decision-making processes shape individual participation, resource distribution, and long-term system dynamics. With a focus on agent-based modeling, the simulation ties together elements of participatory dynamics, resource allocation, and group decision effects in a controlled, evolving system.</p>"},{"location":"concept/#project-summary","title":"Project Summary","text":"<p>DemocracySim is set in a grid-based environment where agents interact with their surroundings and participate in group decision-making through elections. The system explores various scenarios and voting rules to understand key dynamics and challenges in democratic participation.</p>"},{"location":"concept/#key-features","title":"Key Features","text":""},{"location":"concept/#simulated-environment","title":"Simulated Environment:","text":"<ul> <li>The grid is designed without boundaries, and each unit (field) within it adopts one of x colors. Fields change color based on election results, with a mutation rate affected by prior outcomes.</li> <li>Groups of fields form territories, which serve as the basis for elections and influence grid evolution.</li> </ul>"},{"location":"concept/#agents","title":"Agents:","text":"<ul> <li>Agents are equipped with a basic artificial intelligence system and operate under a \"top-down\" model, learning decision-making strategies via training.</li> <li>Each agent has a limited budget and must decide whether to participate in elections.</li> <li>Agents have individual preferences over colors (called personalities) and are divided into y randomly distributed personality types. (The distribution of types forms majority-minority situations.)</li> </ul>"},{"location":"concept/#elections-and-rewards-two-dilemmas","title":"Elections and Rewards (Two Dilemmas):","text":"<ol> <li> <p>Elections:</p> <ul> <li>Elections concern the frequency distribution of field colors in a given territory, representing an \"objective truth\" aimed at emulating wise group decisions.</li> <li>For an intuitive understanding, the election addresses the question: \"What is \u2014 or should be \u2014 the current color distribution within your territory?\"</li> </ul> </li> <li> <p>Rewards:</p> <ul> <li>Rewards are distributed to all agents in the territory, regardless of participation (participation dilemma).   These rewards consist of:<ul> <li>Base reward: Distributed equally based on how well agents guess the true color distribution.</li> <li>Personal reward: Allocated based on the alignment between election results and agent preferences, introducing a second dilemma:<ul> <li>Should agents vote selfishly (favoring their preferences) or vote with a focus on the group's accuracy (collective good)?</li> </ul> </li> </ul> </li> </ul> </li> </ol>"},{"location":"concept/#simulation-metrics-indicators","title":"Simulation Metrics / Indicators","text":""},{"location":"concept/#participation-rate-aggregate-behavioral-variable","title":"Participation Rate (Aggregate Behavioral Variable)","text":"<ul> <li>Measures the percentage of agents actively participating in elections at a given time.</li> <li>Helps evaluate the participation dilemma by analyzing participation across the group and comparing rates for majority vs. minority groups.</li> </ul>"},{"location":"concept/#altruism-factor-individual-behavioral-variable","title":"Altruism Factor (Individual Behavioral Variable)","text":"<ul> <li>Quantifies the extent to which agents prioritize the collective good (e.g., the group's accuracy in guessing) over individual preferences, including cases of non-cooperation with a majority they belong to when it conflicts with the (expected) collective good.</li> <li>Additionally, tracking the average altruism factor of personality groups can provide insights, though this may be misleading if agents/groups do not participate.</li> </ul>"},{"location":"concept/#gini-index-inequality-metric","title":"Gini Index (Inequality Metric)","text":"<ul> <li>Measures the inequality in asset distribution among agents within the system.</li> <li>Ranges from 0 (perfect equality) to 1 (maximum inequality, where one agent holds all assets).</li> <li>Offers insights into how electoral decisions impact wealth/resource distribution over time.</li> </ul>"},{"location":"concept/#collective-accuracy","title":"Collective Accuracy","text":"<ul> <li>Measures how accurately the group, as a collective, estimates the actual color distribution.</li> <li>This directly influences rewards and serves as a metric for evaluating group performance against a ground truth.</li> </ul>"},{"location":"concept/#diversity-of-shared-opinions","title":"Diversity of Shared Opinions","text":"<ul> <li>Evaluates the variation in agents' expressed preferences.</li> <li>To track whether participating agents provide diverse input or converge on overly similar opinions (e.g., due to majority influence).</li> </ul>"},{"location":"concept/#distance-to-optimum","title":"Distance to Optimum","text":"<p>In principle, the optimal decision can be determined based on a predefined goal, allowing the distance between this optimum and the group's actual decision to be measured.</p> <p>Possible predefined goals include:</p> <ol> <li> <p>Utilitarian:</p> <ul> <li>Maximize the total sum of distributed rewards.</li> <li>Focus on the total reward, regardless of how it is distributed.</li> </ul> </li> <li> <p>Egalitarian:</p> <ul> <li>Minimize the overall inequality in individual rewards.</li> <li>Focus on fairness, aiming for a more just distribution of rewards among members.</li> </ul> </li> <li> <p>Rawlsian:</p> <ul> <li>Maximize the rewards for the poorest (personality-based) group.</li> <li>Inspired by John Rawls' Difference Principle, the focus is on improving the well-being of the least advantaged group while tolerating inequalities elsewhere.</li> </ul> </li> </ol>"},{"location":"concept/#research-questions","title":"Research Questions","text":"<p>DemocracySim seeks to answer several critical questions:</p> <ul> <li>Do different voting procedures produce varying dynamics, and if so, how?</li> <li>How do minority and majority agent types behave in collective decision-making?</li> <li>What are the long-term effects of (non-)participation on the system?</li> <li>How does wealth distribution impact participation and welfare in the simulation?</li> </ul>"},{"location":"concept/#broader-implications","title":"Broader Implications","text":"<p>This project offers a controlled testbed for understanding the complex interplay of individual and collective interest in democratic systems. DemocracySim has the potential to reveal valuable insights into real-world voting dynamics.</p>"},{"location":"mesa_docs/","title":"Mesa","text":"<p>See the official Mesa documentation for detailed information.</p>"},{"location":"mesa_docs/#a-python-library-for-agent-based-modeling","title":"A Python Library for Agent-Based Modeling","text":"<p>Mesa<sup>1</sup> is a Python library designed for creating agent-based models (ABMs)<sup>2</sup>.  It provides tools to define, run, and visualize models in which individual entities, called agents, interact within an environment (the model).  Mesa is highly flexible, allowing to simulate complex systems and observe emergent behaviors arising from simple rules.</p>"},{"location":"mesa_docs/#agent-based-modeling-and-complex-societal-questions","title":"Agent-Based Modeling and Complex Societal Questions","text":"<p>Multi-agent-based simulation is a valuable tool to research voting rules and collective decision-making as it allows for the modeling of very complex interactions that are challenging to capture with traditional methods<sup>3</sup>. ABM is mainly used to research and analyze complex relationships.  The focus is on understanding how individual behaviors and interactions lead to collective outcomes.  It is often used in fields like social sciences, economics,  and environmental science to model and analyze scenarios that are impractical to study otherwise.</p> <p> Figure 1: Example of a simple Schelling-Model in Mesa</p> <ol> <li> <p>Jackie Kazil, David Masad, and Andrew Crooks. Utilizing Python for Agent-Based Modeling: The Mesa Framework. In: Social, Cultural, and Behavioral Modeling. Ed. by Robert Thomson, Halil Bisgin, Christopher Dancy, Ayaz Hyder, and Muhammad Hussain. Cham: Springer International Publishing, 2020, pp. 308\u2013317\u00a0\u21a9</p> </li> <li> <p>Dirk Helbing. Agent-based modeling. In: Social self-organization: Agent-based simulations and experiments to study emergent social behavior. Springer, 2012, pp. 25\u201370\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"teaser/","title":"Navigating the Future: The Role of Democratic Governance to Solve Global Challenges and AI Risks","text":"<p>In a world brimming with complexities and uncertainties, we find ourselves at a crossroads.  We face a myriad of pressing global challenges \u2014 from climate change<sup>9</sup> and social inequality<sup>8</sup>  to the ethical dilemmas posed by the rapid advancement of artificial intelligence (AI)<sup>4</sup>.</p> <p>Imagine a future where AI surpasses individual human intelligence across many domains<sup>3</sup>. How do we safely integrate this expertise into existing governance structures? At present, AI algorithms, mostly devoid of ethical considerations, perpetuate biases<sup>5</sup> and render decisions  that lack transparency or foresight<sup>2</sup>.  How can we harness this burgeoning power effectively while mitigating its risks?</p> <p>If you were forced to give a single solution to all the world's most pressing problems, what would it be? Universal education? Innovation and Technology? Or even AI?</p>"},{"location":"teaser/#the-imperative-of-collective-intelligence","title":"The Imperative of Collective Intelligence","text":"<p>I posit that \"enhancing governance\" is the linchpin around which all solutions revolve.  In other words, we must elevate our collective intelligence<sup>6</sup> above all else  to safely and effectively navigate our future.</p> <p>In an era increasingly defined by the advent of general AI,  we have more reason than ever to focus on democratizing governance  and aligning AI development symbiotically within it<sup>7</sup>. Because at the heart of the AI dilemma lies the need for ethical decision-making and strategic planning \u2014 a terrain  where AI's weaknesses are most pronounced. The principles of democratic governance offer a sturdy foundation,  providing the checks and balances necessary to guide AI development in line with human values and long-term welfare.</p> <p></p> <p>However, the importance of democratic decision-making transcends the realm of AI.  It extends to our collective response to all global challenges, ensuring policies are inclusive,  coherent, and accountable. Democratic governance fosters economic stability, social justice, and  environmental stewardship \u2014 essential ingredients for navigating the complexities of the 21st century.</p>"},{"location":"teaser/#using-multi-agent-based-simulations","title":"Using Multi-Agent-Based Simulations","text":"<p>To embark on improving governance, we must first delve into research.  Traditionally, collective decision-making research has focused  on evaluating methods against reasonable assumptions (like Pareto optimality, Condorcet consistency,  non-dictatorship, etc.), demonstrating mathematically that no method will ever satisfy all criteria<sup>1</sup>.  But the complexity of the problem is even greater when we consider collective decision-making in real-world societies. Real-world democratic governance goes far beyond merely aligning individual interests \u2014 it involves intricate  path dependencies from past decisions, disinformation and lack of participation, to name just the most obvious.</p> <p>Addressing these challenges requires a novel approach.  This research aims to pioneer a new path by incorporating these complexities through multi-agent-based simulations.</p> <p>While the model and research inquiries within the proposed master thesis  can only represent this approach in its infancy, the potential of multi-agent-based modeling  to eventually encapsulate all essential facets of real-world democratic governance can hardly be overstated<sup>10</sup>. To the best of our knowledge, this approach has not been systematically applied to researching social choice  or collective decision-making. It stands poised to boost what may be the most underestimated cornerstone of human society: our collective intelligence.</p>"},{"location":"teaser/#references","title":"References","text":"<ol> <li> <p>Felix Brandt, Vincent Conitzer, Ulle Endriss, J\u00e9r\u00f4me Lang, and Ariel D. Procaccia, editors. Handbook of Computational Social Choice. Cambridge University Press, 2016\u00a0\u21a9</p> </li> <li> <p>Jana Fehr, Brian Citro, Rohit Malpani, Christoph Lippert, and Vince I Madai. A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare. Frontiers in Digital Health, 6:1267290, 2024.\u00a0\u21a9</p> </li> <li> <p>Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. Viewpoint: When will AI exceed human performance? evidence from AI experts. J. Artif. Intell. Res., 62:729\u2013754, 2018.\u00a0\u21a9</p> </li> <li> <p>Benjamin Hilton. Preventing an AI-related catastrophe: AI might bring huge benefits \u2014 if we avoid the risks.\u00a0\u21a9</p> </li> <li> <p>Susan Leavy, Barry O\u2019Sullivan, and Eugenia Siapera. Data, power and bias in artificial intelligence. CoRR, abs/2008.07341, 2020.\u00a0\u21a9</p> </li> <li> <p>Jan Marco Leimeister. Collective intelligence. Business &amp; Information Systems Engineering, 2:245\u2013248, 2010.\u00a0\u21a9</p> </li> <li> <p>Thomas W Malone. Superminds: The surprising power of people and computers thinking together. Little, Brown Spark, 2018.\u00a0\u21a9</p> </li> <li> <p>Thomas Piketty. Das Kapital im 21. Jahrhundert. CH Beck, 2014.\u00a0\u21a9</p> </li> <li> <p>Hans-Otto P\u00f6rtner, Debra C Roberts, H Adams, C Adler, P Aldunce, E Ali, R Ara Begum, R Betts, R Bezner Kerr, R Biesbroek, et al. Climate change 2022: Impacts, adaptation and vulnerability. IPCC Sixth Assessment Report, 2022.\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"technical/approval_voting/","title":"Problem of threshold in approval voting","text":"<p>If we choose an architecture in which voters always provide a sum-normalized preference vector for all voting rules, then approval voting has to have a threshold value to determine which options are approved. This may take autonomy away from the voters, but it ensures that every voting rule is based on the same conditions increasing comparability. It may also help to add more rules later on.</p>"},{"location":"technical/approval_voting/#idea","title":"Idea","text":"<p>Setting a fixed threshold of $ \\frac{1}{m} $ for approval voting where m is the number of options.</p>"},{"location":"technical/approval_voting/#definitions-and-setup","title":"Definitions and Setup","text":"<ul> <li>Sum-normalized vector: A preference vector $ \\mathbf{p} = (p_1, p_2, \\ldots, p_m) $ where each entry $ p_i $ represents the preference score for option $ i $, with the constraint $ \\sum_{i=1}^m p_i = 1 $.</li> <li>Threshold: A fixed threshold of $ \\frac{1}{m} $ is used to determine approval. If $ p_i \\geq \\frac{1}{m} $, the option $ i $ is considered \"approved.\"</li> </ul>"},{"location":"technical/approval_voting/#average-number-of-approved-values","title":"Average Number of Approved Values","text":"<p>To find the average number of values approved, let's consider how many entries $ p_i $ would meet the threshold $ p_i \\geq \\frac{1}{m} $.</p> <ol> <li>Expectation Calculation:</li> <li>The expected number of approvals can be found by looking at the expected value of each $ p_i $ being greater than or equal to $ \\frac{1}{m} $.</li> <li> <p>For a sum-normalized vector, the average value of any $ p_i $ is $ \\frac{1}{m} $. This is because the sum of all entries equals 1, and there are $ m $ entries.</p> </li> <li> <p>Probability of Approval:</p> </li> <li> <p>If the vector entries are randomly distributed, the probability of any given $ p_i $ being above the threshold is approximately 50%. This stems from the fact that the mean is $ \\frac{1}{m} $, and assuming a uniform or symmetric distribution around this mean, half the entries would be above, and half below, in expectation.</p> </li> <li> <p>Expected Number of Approvals:</p> </li> <li>Since each entry has a 50% chance of being above $ \\frac{1}{m} $ in a uniform random distribution, the expected number of approved values is $ \\frac{m}{2} $.</li> </ol> <p>Therefore, on average, $ \\frac{m}{2} $ values will be approved.</p>"},{"location":"technical/approval_voting/#range-of-the-number-of-approved-values","title":"Range of the Number of Approved Values","text":"<p>The number of approved values can vary depending on how the preference scores are distributed. Here's the possible range:</p> <ol> <li>Minimum Approved Values:</li> <li> <p>If all entries are below $ \\frac{1}{m} $, then none would be approved. However, given the constraint that the vector sums to 1, at least one entry must be $ \\frac{1}{m} $ or higher. Hence, the minimum number of approved values is 1.</p> </li> <li> <p>Maximum Approved Values:</p> </li> <li>The maximum occurs when as many values as possible are at least $ \\frac{1}{m} $. In the extreme case, you could have all $ m $ entries equal $ \\frac{1}{m} $ exactly, making them all approved. Thus, the maximum number of approved values is m.</li> </ol>"},{"location":"technical/approval_voting/#conclusion","title":"Conclusion","text":"<ul> <li>Average number of approved values: $ \\frac{m}{2} $.</li> <li>Range of approved values: From 1 (minimum) to $ m $ (maximum).</li> </ul> <p>Hence, in theory, voters can still approve between 1 and $ m $ options,  giving them the whole range of flexibility that approval voting offers.</p>"},{"location":"technical/approval_voting/#possibility-for-improvement","title":"Possibility for improvement","text":"<p>We should consider implementing rule-specific voting into the agent's decision-making process instead of leaving all rule-specifics to the aggregation process. This would allow for a more realistic comparison of the rules. For some rules, it would also give opportunities to significantly speed up the simulation process.</p>"},{"location":"technical/preference_relations/","title":"How preference relations are defined and represented in the system","text":""},{"location":"technical/preference_relations/#introduction","title":"Introduction","text":"<p>...</p>"},{"location":"technical/preference_relations/#definition","title":"Definition","text":"<p>A preference relation \\tau\\in\\mathbb{R}_{\\geq 0}^m is a numpy vector of length m,  where m is the number of options and each element \\tau[i] represents the normalized preference for option i, with \\sum_{\\tau}=1.</p>"},{"location":"technical/preference_relations/#why-using-sum-normalization","title":"Why using sum normalization?","text":"<p>In computational social choice, sum normalization is more common than magnitude normalization.  This is because sum normalization aligns well with the interpretation of preference vectors as distributions  or weighted votes, which are prevalent in social choice scenarios.</p>"},{"location":"technical/preference_relations/#why-using-non-negative-values","title":"Why using non-negative values?","text":"<p>The preference values \\tau[i] are non-negative because they represent the strength of preference for each option. Equvalently, they can be interpreted as the probability of selecting each option  or the (inverted or negative) distance of an option to the agents' ideal solution.</p>"},{"location":"de/mesa_docs/","title":"Mesa","text":"<p>F\u00fcr ausf\u00fchrlichere Informationen siehe die offizielle Mesa documentation.</p>"},{"location":"de/mesa_docs/#die-python-bibliothek-mesa-fur-agentenbasierte-modellierung","title":"Die Python-Bibliothek \"Mesa\" f\u00fcr agentenbasierte Modellierung","text":"<p>Mesa<sup>1</sup> ist eine Python-Bibliothek, die speziell f\u00fcr die Erstellung von agentenbasierten Modellen (ABMs)<sup>2</sup> entwickelt wurde.  Diese Modelle erm\u00f6glichen es, Individuen, sogenannte Agenten, innerhalb einer definierten Umgebung (dem Model) interagieren zu lassen.  Mesa bietet Werkzeuge zur Definition, Ausf\u00fchrung und Visualisierung solcher Modelle und Agenten.  Dies erm\u00f6glicht die Simulation komplexer Systeme sowie die Beobachtung emergenter Verhaltensweisen,  welche oft bereits aus sehr einfachen Regeln hervorgehen.</p>"},{"location":"de/mesa_docs/#agentenbasierte-modellierung-bei-der-untersuchung-komplexer-gesellschaftlicher-fragen","title":"Agentenbasierte Modellierung bei der Untersuchung komplexer gesellschaftlicher Fragen","text":"<p>Multi-Agenten-Simulationen bieten eine wertvolle Erg\u00e4nzung bei der Erforschung von Wahlregeln und kollektiven Entscheidungsprozessen.  Diese Methode erm\u00f6glicht die Modellierung sehr komplexer Interaktionen, die mit traditionellen Methoden schwer zu erfassen sind<sup>3</sup>.  Agentenbasierte Modelle dienen haupts\u00e4chlich der Erforschung und Analyse komplexer Zusammenh\u00e4nge.  Das Hauptaugenmerk liegt darauf zu verstehen, wie individuelle Verhaltensweisen und Interaktionen zu kollektiven Ergebnissen f\u00fchren.  Sie werden h\u00e4ufig in den Sozialwissenschaften, der Wirtschaftswissenschaft und der Umweltforschung eingesetzt,  um Szenarien zu modellieren und zu analysieren, die anderweitig schwer zu untersuchen sind.</p> <p> Bild 1: Beispiel eines simplen Schelling-Modells in Mesa</p> <ol> <li> <p>Jackie Kazil, David Masad, and Andrew Crooks. Utilizing Python for Agent-Based Modeling: The Mesa Framework. In: Social, Cultural, and Behavioral Modeling. Ed. by Robert Thomson, Halil Bisgin, Christopher Dancy, Ayaz Hyder, and Muhammad Hussain. Cham: Springer International Publishing, 2020, pp. 308\u2013317\u00a0\u21a9</p> </li> <li> <p>Dirk Helbing. Agent-based modeling. In: Social self-organization: Agent-based simulations and experiments to study emergent social behavior. Springer, 2012, pp. 25\u201370\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"},{"location":"de/teaser/","title":"Zukunft gestalten: Demokratie-Forschung zur Bew\u00e4ltigung globaler Herausforderungen","text":"<p>In einer Welt voller Komplexit\u00e4t und Unsicherheit stehen wir an einem Scheideweg.  Dringende globale Herausforderungen wie der Klimawandel<sup>9</sup>, soziale Ungleichheit<sup>8</sup> und die ethischen Dilemmata<sup>4</sup>,  die mit dem rasanten Fortschritt k\u00fcnstlicher Intelligenz (KI) einhergehen, dr\u00e4ngen nach L\u00f6sungen.</p> <p>Eine Zukunft, in der KI die menschliche Intelligenz in vielen Bereichen \u00fcbertrifft, erscheint zunehmend wahrscheinlich<sup>3</sup>.  K\u00f6nnen wir diese Technologie sinnvoll und sicher in bestehende Governance-Verfahren und Strukturen integrieren?  Aktuelle KI arbeitet oft ohne ethische \u00dcberlegungen, erh\u00e4lt Vorurteile aufrecht<sup>5</sup>  und trifft Entscheidungen mit fragw\u00fcrdiger Transparenz und Weitsicht<sup>2</sup>. </p> <p>Wenn Sie eine einzige L\u00f6sung f\u00fcr die dringendsten Probleme der Welt nennen m\u00fcssten, welche w\u00e4re das?  Umfassende Bildung? Innovation und Technologie? Oder gar KI?</p>"},{"location":"de/teaser/#die-bedeutung-kollektiver-intelligenz","title":"Die Bedeutung kollektiver Intelligenz","text":"<p>Ich behaupte, dass die Verbesserung der gesellschaftlichen demokratischen Verwaltung (Governance) der Dreh- und Angelpunkt aller m\u00f6glichen L\u00f6sungen ist.  Mit anderen Worten: Wir m\u00fcssen kollektiv intelligenter<sup>6</sup> werden,  um unsere Zukunft sicher und effektiv zu gestalten.</p> <p>Mit dem Ausblick auf eine aufkommende Allgemeine KI gilt es mehr denn je, demokratische Selbstverwaltung zu st\u00e4rken, auszubauen und jegliche KI-Entwicklung symbiotisch in sie einzuhegen<sup>7</sup>.  Im Kern des KI-Dilemmas liegt die Notwendigkeit ethischer Entscheidungsfindung und strategischer Planung \u2013 also eben  jenes Bereichs, in dem die Schw\u00e4chen k\u00fcnstlicher Intelligenz am deutlichsten zutage treten.  Demokratische Selbstbestimmung von Menschen kann genau diese L\u00fccke f\u00fcllen.  Sie bietet die notwendigen Schranken und Kontrollen,  um KI-Entwicklung mit menschlichen Werten und langfristigem Wohlergehen in Einklang zu bringen.</p> <p></p> <p>Die Bedeutung demokratischer Entscheidungsfindung geht jedoch \u00fcber den Bereich der KI hinaus.  Sie erstreckt sich auf unsere kollektive Reaktion auf alle globalen Herausforderungen und stellt sicher,  dass politische Ma\u00dfnahmen inklusiv, koh\u00e4rent und rechenschaftspflichtig sind.  Demokratische Verwaltung f\u00f6rdert wirtschaftliche Stabilit\u00e4t,  soziale Gerechtigkeit und Umweltverantwortung \u2013 wesentliche Bestandteile,  um die Komplexit\u00e4ten des 21. Jahrhunderts zu bew\u00e4ltigen.</p>"},{"location":"de/teaser/#einsatz-von-multi-agenten-basierten-simulationen","title":"Einsatz von Multi-Agenten-basierten Simulationen","text":"<p>Um demokratische Prozesse zu verbessern, m\u00fcssen wir zun\u00e4chst in die Forschung eintauchen.  Traditionell konzentrierte sich die Erforschung kollektiver Entscheidungsfindung darauf,  Methoden anhand vern\u00fcnftig erscheinender Annahmen  (wie dem Pareto-Prinzip, Condorcet-Kriterium, Nicht-Diktatur usw.)  zu bewerten und schlie\u00dflich mathematisch zu beweisen, dass keine Methode jemals alle Kriterien erf\u00fcllen wird<sup>1</sup>.  Es handelt sich bei kollektiven Entscheidungen also bereits theoretisch um ein nicht-triviales Problem. Doch die wahre Komplexit\u00e4t kollektiver Entscheidungsfindung, n\u00e4mlich die im realen Kontext, in realen Gesellschaften, ist noch um einiges gr\u00f6\u00dfer.  Reale demokratische Verwaltung geht weit \u00fcber das blo\u00dfe Ineinklangbringen individueller Pr\u00e4ferenzen hinaus \u2013 sie  beinhaltet Pfadabh\u00e4ngigkeiten vergangener Entscheidungen, Desinformation und mangelnde Beteiligung,  um nur einige offensichtliche Herausforderungen zu nennen.</p> <p>Um diese Herausforderungen zu bew\u00e4ltigen, sind innovative Ans\u00e4tze erforderlich.  Das vorliegende Projekt zielt darauf ab, langfristig m\u00f6glichst viele dieser Einfl\u00fcsse durch Multi-Agenten-basierte  Simulationen integriert zu untersuchen.</p> <p>Das Modell und die Forschungsfragen einer Masterarbeit  k\u00f6nnen diesen Ansatz nat\u00fcrlich nur in ihren absoluten Grundz\u00fcgen darstellen.  Soweit uns bekannt, wurde dieser Ansatz noch nicht systematisch in der  Erforschung kollektiver Entscheidungsfindung angewandt, weshalb wir auch sehr grundlegend beginnen. Dennoch sollte das Potenzial von Multi-Agenten-basiertem Modellieren nicht untersch\u00e4tzt werden.  Langfristig wird dadurch sehr wahrscheinlich erm\u00f6glicht,  alle wesentlichen Aspekte der realen demokratischen Selbstverwaltung zu untersuchen<sup>10</sup>. Die kollektive Intelligenz einer Gesellschaft durch verbesserte Governance-Verfahren zu st\u00e4rken,  ist wahrscheinlich der effektivste Weg und unser gr\u00f6\u00dfter Hebel, die Herausforderungen unserer Zeit zu meistern.</p>"},{"location":"de/teaser/#quellen","title":"Quellen","text":"<ol> <li> <p>Felix Brandt, Vincent Conitzer, Ulle Endriss, J\u00e9r\u00f4me Lang, and Ariel D. Procaccia, editors. Handbook of Computational Social Choice. Cambridge University Press, 2016\u00a0\u21a9</p> </li> <li> <p>Jana Fehr, Brian Citro, Rohit Malpani, Christoph Lippert, and Vince I Madai. A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare. Frontiers in Digital Health, 6:1267290, 2024.\u00a0\u21a9</p> </li> <li> <p>Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. Viewpoint: When will AI exceed human performance? evidence from AI experts. J. Artif. Intell. Res., 62:729\u2013754, 2018.\u00a0\u21a9</p> </li> <li> <p>Benjamin Hilton. Preventing an AI-related catastrophe: AI might bring huge benefits \u2014 if we avoid the risks.\u00a0\u21a9</p> </li> <li> <p>Susan Leavy, Barry O\u2019Sullivan, and Eugenia Siapera. Data, power and bias in artificial intelligence. CoRR, abs/2008.07341, 2020.\u00a0\u21a9</p> </li> <li> <p>Jan Marco Leimeister. Collective intelligence. Business &amp; Information Systems Engineering, 2:245\u2013248, 2010.\u00a0\u21a9</p> </li> <li> <p>Thomas W Malone. Superminds: The surprising power of people and computers thinking together. Little, Brown Spark, 2018.\u00a0\u21a9</p> </li> <li> <p>Thomas Piketty. Das Kapital im 21. Jahrhundert. CH Beck, 2014.\u00a0\u21a9</p> </li> <li> <p>Hans-Otto P\u00f6rtner, Debra C Roberts, H Adams, C Adler, P Aldunce, E Ali, R Ara Begum, R Betts, R Bezner Kerr, R Biesbroek, et al. Climate change 2022: Impacts, adaptation and vulnerability. IPCC Sixth Assessment Report, 2022.\u00a0\u21a9</p> </li> <li> <p>Robert L Axtell and J Doyne Farmer. Agent-based modeling in economics and finance: Past, present, and future. In: Journal of Economic Literature (2022), pp. 1\u201310\u00a0\u21a9</p> </li> </ol>"}]}